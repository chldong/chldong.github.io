---
layout: post
title:  "基于CNN技术的OCR"
date:   2022-03-08
---
## 1 项目介绍

AI发证系统的核心流程是采用OCR技术识别空白证明编号，并并将编号发送后台接口，取出数据，打印含有完整信息的证书，并交付用户。

### 1.1 光学字符识别OCR

OCR （Optical Character Recognition，光学字符识别）是指电子设备（例如扫描仪或数码相机）检查纸上打印的字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机文字的过程；即，针对印刷体字符，采用光学的方式将纸质文档中的文字转换成为黑白点阵的图像文件，并通过识别软件将图像中的文字转换成文本格式，供文字处理软件进一步编辑加工的技术。如何除错或利用辅助信息提高识别正确率，是OCR最重要的课题，ICR（Intelligent Character Recognition）的名词也因此而产生。衡量一个OCR系统性能好坏的主要指标有：拒识率、误识率、识别速度、用户界面的友好性，产品的稳定性，易用性及可行性等。

目前通常使用如下几种方法：

| 方法名称 | 相关要点 |
| ------ | ------ |
| tesseract | 仅适合识别没有干扰和扭曲的图片，训练起来很麻烦 |
| 其他开源识别库 | 不够通用，识别率未知 |
| 付费OCR API | 需求量大的情形成本很高 |
| 图像处理+机器学习分类算法 | 涉及多种技术，学习成本高，且不通用 |
| 卷积神经网络 | 一定的学习成本，算法适用于多类字符识别 |

这里说一下使用传统的**图像处理和机器学习算法**，涉及多种技术：  

1. 图像处理

- 前处理（灰度化、二值化）
- 图像分割
- 裁剪（去边框）
- 图像滤波、降噪
- 去背景
- 颜色分离
- 旋转

2. 机器学习

- KNN
- SVM

使用这类方法对使用者的要求较高，且由于图片的变化类型较多，处理的方法不够通用，经常花费很多时间去调整处理步骤和相关算法。

而使用**卷积神经网络**，只需要通过简单的前处理，就可以实现大部分防伪型证书编号的端到端识别，效果很好，通用性很高。

![卷积神经公式](/source/images/卷积神经公式.png)

## 2 如何使用
### 2.1 数据集

得到原始数据集，可以存放在`./sample/origin`目录中。  
为了便于处理，图片最好以（标签_序列号.后缀）格式命名。
  
如果你没有训练集，你可以使用`import_cat.py`文件批量截取预先准备的原始证明扫描件。

## 2.2 配置文件

开始训练前，需要自行**修改相关配置文件**`conf/sample_config.json`。

```
{
  "origin_image_dir": "sample/origin/",  # 原始文件
  "new_image_dir": "sample/new_train/",  # 新的训练样本
  "train_image_dir": "sample/train/",    # 训练集
  "test_image_dir": "sample/test/",      # 测试集
  "api_image_dir": "sample/api/",        # api接收的图片储存路径
  "cut_image_dir": "sample/online/",     # 从摄像机截取的图片
  "local_image_dir": "sample/local/",    # 本地保存图片的路径
  "model_save_dir": "model/",            # 模型文件路径
  "image_width": 500,                    # 图片宽度
  "image_height": 100,                   # 图片高度
  "max_code": 10,                        # 字符个数
  "image_suffix": "png",                 # 图片文件后缀
  "char_set": "0123456789",              # 字符类别
  "use_labels_json_file": false,                       # 是否开启读取`labels.json`内容
  "remote_url": "http://127.0.0.1:6100/cam1/",      # 编码获取地址
  "cycle_stop": 3000,                                  # 启动任务后的训练指定次数后停止
  "acc_stop": 0.99,                                    # 训练到指定准确率后停止
  "cycle_save": 500,                                   # 训练指定次数后定时保存模型
  "enable_gpu": 0,                                     # 是否开启GUP训练
  "train_batch_size": 128,                             # 训练时每次使用的图片张数，如果CPU或者GPU内存太小可以减少这个参数
  "test_batch_size": 100                               # 每批次测试时验证的图片张数，不要超过数据集的总数
}

```

关于`字符类别`，假设你的样本是中文，你可以使用`tools/collect_labels.py`脚本进行标签的统计。
会生成文件`gen_image/labels.json`存放所有标签，在配置文件中设置`use_labels_json_file = True`开启读取`labels.json`内容作为`结果类别`。

## 2.3 验证和拆分数据集

此功能会校验原始图片集的尺寸和测试图片是否能打开，并按照19:1的比例拆分出训练集和测试集。  
所以需要分别创建和指定三个文件夹：origin，train，test用于存放相关文件。

也可以修改为不同的目录，但是最好修改为绝对路径。  
文件夹创建好之后，执行以下命令即可：

```
python3 verify_and_split_data.py
```

一般会有类似下面的提示

```
>>> 开始校验目录：[sample/origin/]
开始校验原始图片集
原始集共有图片: 1001张
====以下1张图片有异常====
[第0张图片] [.DStore] [文件后缀不正确]
========end
开始分离原始图片集为：测试集（5%）和训练集（95%）
共分配1000张图片到训练集和测试集，其中1张为异常留在原始目录
测试集数量为：50
训练集数量为：950
>>> 开始校验目录：[sample/new_train/]
【警告】找不到目录sample/new_train/，即将创建
开始校验原始图片集
原始集共有图片: 0张
====以下0张图片有异常====
未发现异常（共 0 张图片）
========end
开始分离原始图片集为：测试集（5%）和训练集（95%）
共分配0张图片到训练集和测试集，其中0张为异常留在原始目录
测试集数量为：0
训练集数量为：0
```

程序会同时校验和分割`origin_image_dir`和`new_image_dir`两个目录中的图片；后续有了更多的样本，可以把样本放在`new_image_dir`目录中再次执行`import_cut`。  
程序会把无效的文件留在原文件夹。  

此外，当你有新的样本需要一起训练，可以放在`sample/new`目录下，再次运行`python3 import_cut.py`即可。  
需要注意的是，如果新的样本中有新增的标签，你需要把新的标签增加到`char_set`配置中或者`labels.json`文件中。

## 2.4 训练模型

创建好训练集和测试集之后，就可以开始训练模型了。  
训练的过程中会输出日志，日志展示当前的训练轮数、准确率和loss。  
**此时的准确率是训练集图片的准确率，代表训练集的图片识别情况**  
例如：

```
第10次训练 >>> 
[训练集] 字符准确率为 0.03000 图片准确率为 0.00000 >>> loss 0.1698757857
[验证集] 字符准确率为 0.04000 图片准确率为 0.00000 >>> loss 0.1698757857
```

字符准确率和图片准确率的解释：

```
假设：有100张图片，每张图片四个字符，共400个字符。我们这里把任务拆分为为需要识别400个字符
字符准确率：识别400的字符中，正确字符的占比。
图片准确率：100张图片中，4个字符完全识别准确的图片占比。
```

这里不具体介绍tensorflow安装相关问题，直奔主题。  
确保图片相关参数和目录设置正确后，执行以下命令开始训练：

```
python3 train_model.py
```

也可以根据`train_model.py`的`main`函数中的代码调用类开始训练或执行一次简单的识别演示。  

由于训练集中常常不包含所有的样本特征，所以会出现训练集准确率是100%而测试集准确率不足100%的情况，此时提升准确率的一个解决方案是增加正确标记后的负样本。

## 2.5 批量验证

使用测试集的图片进行验证，输出准确率。  

```
python3 test_batch.py
```

同样可以根据`main`函数中的代码调用类开始验证。

## 2.6 启动WebServer

项目已经封装好加载模型和识别图片的类，启动`web server`后调用接口就可以使用识别服务。  
启动`web server`

```
python3 webserver_recognize_api.py
```

接口url为`http://127.0.0.1:6000/b`

## 2.7 调用接口识别

使用requests调用接口:

```
url = "http://127.0.0.1:6000/b"
files = {'image_file': (image_file_name, open('captcha.jpg', 'rb'), 'application')}
r = requests.post(url=url, files=files)
```

返回的结果是一个json：

```
{
    'time': '1542017705.9152594',
    'value': 'H1234567890',
}
```

文件`recognize_local.py`是使用接口识别本地的例子，这个例子运行成功，那么本地部署的一套流程基本上是走了一遍了。  
在线识别是项目中常用部署场景，文件`recognize_online.py`是使用接口在线识别的例子，参见：`## 2.11 在线识别`。

## 2.8 部署

部署的时候，把`webserver_recognize_api.py`文件的最后一行修改为如下内容：

```
app.run(host='0.0.0.0',port=5000,debug=False)
```

然后开启端口访问权限，就可以通过外网访问了。  
另外为了开启多进程处理请求，可以使用uwsgi+nginx组合进行部署。  
这部分可以参考：[Flask部署选择](http://docs.jinkan.org/docs/flask/deploying/index.html)

## 2.9 部署多个模型

部署多个模型:
在`webserver_recognize_api.py`文件汇总，新建一个Recognizer对象；  
并参照原有`up_image`函数编写的路由和识别逻辑。

```
Q = Recognizer(image_height, image_width, max_code, char_set, model_save_dir)
```

注意修改这一行：

```
value = Q.rec_image(img)
```

## 2.10 在线识别

在线识别是项目中常用部署场景，即实时获取目标证明编号来调用接口进行识别。  
为了测试的完整性，这里搭建了一个摄像机截取证明编号获取接口，通过执行下面的命令启动：  

```
python webserver_cat_image.py
```

启动后通过访问此地址：`http://127.0.0.1:6100/cut/`可以接收到证明扫描图片的二进制流文件。  
具体进行在线识别任务的demo参见：`recognize_online.py`。  

# 3 数据统计

## 3.1 训练数据统计

由于很多同学提出，“需要训练多久呀？”、“准确率可以达到多少？”、“为什么我的准确率一直是0？”类似的疑问。  
这一小节，使用默认配置，把训练过程中的数据做了统计，给大家做一个展示。  
本次测试条件如下：

- 证书编号：本项目自带截取证书编号程序，1位大写字母+10位数字
- 数量：20000张
- 计算引擎：GPU
- GPU型号：T4显卡
  
经过测试：
5000次，25分钟，**训练集**字符准确率84%，图片准确率51%；  
9190次，46分钟，**训练集**字符准确率100%，图片准确率100%；  
12000，60分钟，**测试集**的准确率基本上已经跑不动了。  

使用`test_batch.py`测试，日志如下：  

```
100个样本识别耗时6.513171672821045秒，准确率37.0%
```



